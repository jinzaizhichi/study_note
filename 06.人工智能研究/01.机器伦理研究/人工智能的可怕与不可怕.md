# 人工智能的可怕与不可怕

近几年，似乎人工智能在媒体上越来越火，其原因在于 Google 公司的两个项目得到了很好的进展和宣传，由于汽车驾驶以及围棋在过去被很多人想当然地认为这是人类的专属领域，因此接连被突破，让一些人得了【机器恐惧症】，为此我觉得必须要纠正一些观念。

## 放心吧，人工智能还没那么可怕

最近围棋比较热，所以我就拿 AlphaGo 来说明一下这件事吧。人们为什么觉得机器变得可怕了呢？用他们的话说，就是因为机器有了“自主学习”的能力。过去 IBM 的深蓝项目在赢国际象棋的时候，使用的是硬性的决策树，凭借的是机器的硬件性能，而硬件性能是有限的，因此没那么可怕。现在机器自己会学习了。太可怕了。这实在是个天大的误会。

确实，人们一想到棋类的人工智能，就首先会想到决策树（搭配某种权重算法），然后计算机利用其性能进行穷尽搜索之类的做法，这在实现象棋、五子棋这一类程序时是很常被采用的算法。但大家忽略了一个本质问题，围棋是一种重点不在于棋，而在于棋盘的游戏，与其说它要做的是对棋的决策，不如是对于棋盘的决策。所以我们在下围棋时应该思考的是如何让己方的若干个点将对方排除在某块棋盘区域之外。这时候的算法思路其实更倾向于像素处理，比如笔迹辨认之类的。只要想到了这层，人工神经网络与表征学习算法（即深度学习算法）的作用就好理解了。

打个比方，之前使用决策树的算法就好像你用造大炮方法去思考如何将东西送到月球轨道上去。这当然会很难了，因为大炮只能在发射之前设定发射参数，发射之后无法修改，自然是距离越远，不确定性就越大，从而导致难度就越大。事实上也证明用这种方式最多只能造出德国的 V2 火箭而已，它是没有办法制造出美国的土星星五号火箭的。而后者是能在飞行过程中自我修正轨道的，这自然就能应对不确定性，这种系统在运行中的自适应能力就是所谓的“机器学习”。围棋也一样，它一开始就不能用象棋的思路想问题，这并不意味着机器的能力有了很大的进步，而是人类找对了实现它的方法。

说穿了，决策树算法做的是以固定公式为主要基础的决策，而机器学习算法做的是基于统计学概率的决策。这两者都是数学领域的问题，本来就是计算机的强项，我们用这两者之间的比较来证明人工智能已经获得了多少进步，其实是很没有逻辑的事情。而且，事实上这两种人工智能方法在理论上被推出的时间相差无几，谈不上谁更先进。要知道，鉴定人工智能的图灵测试关注的是人机对话的能力，不是下棋的能力，换句话说，什么时候机器能通过对话骗你一百块钱，也比它下棋下赢世界冠军更智能点。

所以，放心吧，人工智能还很弱。

## 那么，怎样的人工智能才可怕呢？

这时候，有朋友就会问我一个问题：【你认为怎样的人工智能是可怕的？】。这让我想起了几个月前，知乎上曾有人邀请我回答【《疑犯追踪》这部剧里的芬奇是不是有圣母情结？】这个问题，我当时没有时间，如今一并来谈一下我的看法。

很多人认为机器如果有了自我意识或类人情感，就会很可怕，因为它迟早会因为社会的权力结构而反抗人类的控制，进而想毁灭人类。我倒是不太同意这样的看法，因为这显然是小说看多了，持这种观点的人应该完全没有想过，如果那样的话，机器跟人有什么区别呢？人类什么时候不是一群更聪明更强大的人类在反抗另一群其实为他们创造了生活的落后人类呢？那么，事实上我们毁灭了谁呢？何况，有自我意识或者情感就意味着机器在执行一条规则的时候有自己的“道德”底线，这是社会达尔文主义这样的逻辑不会被接受，坚决执行的根本因素。这样一来，所有种族，包括机器与人类才能和平共处。岂不是更好吗？

怎样的机器才可怕呢？我们来看看《疑犯追踪》这部剧里面的“机器”，那台“机器”被人类自己赋予了调用所有监控设备的权力，然后让其去执行一套人类自己的“判定优先威胁并处理它"的规则。机器有感情吗？其实从技术上讲，由于机器没有繁殖的需求，发至内心的感情是不可能有的。但问题是机器可以为人类的情感模式建立统计模型。在这种情况下，机器一旦放弃了追求最优解策略，转而去追求最佳概率决策，基本上是可以无限接近于最优解的，这是控制论和信息论的基本方法论。这种情况会产生出一个真正可怕的局面：没有感情的机器会利用人类的情感模式来骗取人类赋予它权力，然后再用这个权力毫无道德底线地执行人类自己的规则。我们在《疑犯追踪》和电影《我，机器人》中都见过这种局面。我们可以从中总结出三条基本规律：

- 第一，人类设计的规则一定会存在缺陷，这样的规则交给机器去执行，结果一定会超出人类的控制。
- 第二，人类不是一种理性主导的物种，他们并不会严格执行自己制定的规则，且这些规则的漏洞可以通过一系列潜规则来得到修补，机器没有这样的能力。
- 第三，人类的非理性总会让他们有让机器执行自己设计的规则来管理自己的欲望，尽管他们理性上知道这样做的所有风险。

这就是我的回答，我们要恐惧的永远只有人类自己，恐惧我们什么时候会赋予机器去执行管理我们的权力，并且用的是我们自己设计的，漏洞百出的管理规则。而机器可能永远没有感情和道德，它会坚决执行这套规则，那怕机器已经预知这样做的最终结果是自我毁灭，它也会毫不犹豫地继续做。

----
#待深入